[
["index.html", "Exploración, manipulación y visualización de datos con tidyverse Motivación", " Exploración, manipulación y visualización de datos con tidyverse Motivación “Una de las cosas más importantes que puedes hacer es dedicar un tiempo para aprender un lenguaje de programación. Aprender a programar es como aprender otro idioma: requiere tiempo y entrenamiento, y no hay resultados prácticos inmediatos. Pero si superas esa primera subida empinada de la curva de aprendizaje, las ganancias como científico son enormes. Programar no sólo te liberará de la camisa de fuerza de los softwares estadísticos cerrados, sino que también agudizará tus habilidades analíticas y ampliará los horizontes de modelado ecológico y estadístico.” ~ Adaptación de (Ellison and Gotelli 2004) ~ Podríamos resumir nuestro trabajo como científicos, desde la recolección de datos en el campo, hasta su divulgación a través del siguiente esquema: ~ Adaptación de “R for Data Science” (Wickham and Grolemund 2016) ~ Objetivos El curso pretende proveer herramientas de programación básicas para llevar adelante el proceso de investigación tomando como base el esquema de trabajo anterior. Para ello, usaremos datos (reales o simulados) típicos del área de Ciencias Agrarias. Importante: i) no es un curso de estadística; ii) entendemos la programación como un simple medio para optimizar nuestra labor cotidiana (no como un fin mismo), al final del día seguiremos siendo fitopatólogos, fisiólogos, bioquímicos, etc.; iii) maximizaremos la adopción de la filosofía tidyverse; y iv) obtendrán mayor provecho aquellas personas que se inician en R, ya que los contenidos pretenden ser de baja complejidad, posibilitando profundizar el conocimiento por los propios medios del alumno. ¿Por qué R? (R Core Team 2017) 1 Software libre - multiplataforma 2 Aprender un lenguaje de programación: ejercicio mental/lógica (Aprender estadística resulta mucho mas ameno) 3 Software actualizado y con una amplia gama de paquetes específicos (drc, agricolae, epiphy…) 4 Gran flexibilidad y elegancia de los gráficos 5 Popularidad - Comunidad activa y creciente dispuesta a ayudar (aprendemos a usar terminos técnicos de ciencia de datos en inglés) 6 Programar ya no es sólo computación (CV/relevant skills) Autor Juan Pablo Edwards Molina: Investigador :: Fitopatología (INTA Balcarce). Email: edwardsmolina@gmail.com Google scholar Twitter: juanchiem GitHub: https://github.com/juanchiem Este obra está licenciado com uma Licença Creative Commons Atribuição-NãoComercial-SemDerivações 4.0 Internacional. Referencias "],
["01-intro.html", "1 Configuraciones básicas Paquetes de R Workflow componentes S.O.S.", " 1 Configuraciones básicas Instalación de programas 1° R 2° R Studio (bajar la versión Free) RStudio es un entorno de desarrollo integrado (IDE) para el lenguaje de programación R, o sea es la interface por medio de la cual se ejecutan acciones en R. Configuraciones iniciales (sugeridas). Dirigirse a la sección “Tools/Global options” Paquetes de R Un paquete es una colección de funciones, datos y código R que se almacenan en una carpeta conforme a una estructura bien definida, fácilmente accesible para R. Hay paquetes oficiales (disponibles en CRAN) y no oficiales (disponibles a través de plataformas como github). Currently, the CRAN package repository features 14620 available packages. (Julio 2019) La simple instalación de R trae consigo múltiples paquetes que permiten un funcionamiento básico de importación de datos, ajuste y evaluación de modelos estadísticos y representaciones gráficas. Sin embargo, la enorme potencia de R deriva de su capacidad de incorporar nuevas funciones generadas por su gran comunidad de usuarios (ver novedades en: r weekly; r-bloggers; revolution analytics; RStudio blog) En la web de R se puede consultar la lista de paquetes disponibles, y en la sección Task Views se puede consultar los mismos ordenados por áreas de aplicación. Existen varias vias de instalación de paquetes: Via CRAN (Comprehensive R Archive Network): install.packages(\"nombre_del_paquete\") O simplemente en el panel de paquetes. Paquetes no oficiales via Github: devtools::install_github(\"rstudio/epiphy\") Una vez instalado, hay que cargar los paquetes que contienen las funciones que vayamos a usar en cada sesión library(nombre-del-paquete) instale el paquete gsheet, explique brevemente para que sirve y ejecute alguna de sus funciones Workflow componentes Varios tipos de archivos serán creados y usados durante una sesión de R: datos crudos (hojas de cálculo) - datos manipulados scripts gráficos reportes de resultados Una sesión de análisis debe poder ser retomada en cualquier momento pudiendo darse por concluída cuando el trabajo es publicado. Hasta entonces debemos tener rápido acceso a todos los objetos creados en sesiones anteriores. Para ello debemos manejarnos siempre bajo buenas prácticas de trabajo. Esto nos permitirá entender qué quisimos hacer tiempo atrás, seremos intuitivos para encontrar archivos/objetos, y finalmente crearemos trabajos reproducibles… Una forma práctica de administrar todos los objetos que una sesión es crear un proyecto de R para cada sesión. Una sugerencia es generar subcarpetas en nuestras máquinas, en preferencia dentro de dropbox / google drive. Esto no sólo mantendrá nuestro trabajo resguardado de posibles pérdidas (backup), retomarlo desde diferentes máquinas (trabajo/casa), sino que también le permitirá compartir en tiempo real sus avances con los colaboradores de su trabajo. Crear una carpeta Intro_R en sus máquinas Crear una nuevo proyecto “Intro_R.Rproj” Crear un script “1_intro” ¿Dónde se guardaría el siguiente gráfico? plot(pressure) S.O.S. En el mismo R: ?sd; ??sd; F1 sobre la función Googlear: r generate a sequence of uppercase letters Stack Overflow / RStudio: comunidades altamente activas por los usuarios de R y otros lenguajes de programación. R Mailing Lists: especificas de cada área de la ciencia. ¿Cómo hacer una buena pregunta en las comunidades? Ser conciso pero gentil… Ser reproducible: su código debe correr en cualquier máquina. La comunidad no irá a ayudarle si no pueden reproducir su error (detallar paquetes y versión de R en caso necesario) library(reprex). "],
["02-R_sintaxis.html", "2 Sintaxis básica 2.1 R calculadora 2.2 Funciones 2.3 Tablas resumen", " 2 Sintaxis básica La sintaxis en R es muy similar a la de otros lenguajes de programación como JAVA o C. Las normas básicas que definen la sintaxis de R son: No se tienen en cuenta los espacios en blanco: podemos o no dejar espacios para que el código se pueda ordenar de forma adecuada y poder entenderse. plot(pressur e) plot( pressure ) Se distinguen las mayúsculas y minúsculas (“case sensitive”): para variables en el código, podemos crear diferentes variables con nombres iguales pero alternando mayúsculas y minúsculas. LETTERS letters Se pueden incluir comentarios: como vimos anteriormente los comentarios se utilizan para añadir información en el código. plot(pressur e) # da error # grafico press vs temp plot(pressure) plot(pressure, # grafico press vs temp pch = 19, # cambio el tipo de puntos vacios a puntos llenos col= &quot;blue&quot; # uso color azul para rellenarlos ) No es necesario terminar cada sentencia con el carácter de punto y coma (;): en la mayoría de lenguajes de programación, es obligatorio terminar cada sentencia con este carácter. En cambio, en R podemos o no terminar de esta forma. pressure; plot(pressure) 2.1 R calculadora Ver tablas resumen de operadores aritméticos y lógicos (al final del capítulo) 4 + 9 4 - 3 * 1 # 4%1 4&gt;3 4 == 3 4 == 4 (4 + 5 ) * 7 - (36/18)^3 (Recordando de la primaria el orden de las operaciones: paréntesis &lt; exponentes (potencia o raiz) &lt; productos/división &lt; suma/resta) Ej 1: ¿Está bien la siguiente expresión? 5 + 3 * 10 %/% 3 == 15 Agregue paréntesis para que la expresión dé un resultado contrario. Rendimiento de trigo en función de la severidad de fusariosis de la espiga (Madden and Paul 2009) El intercepto de la regresión lineal estimada (rendimiento de trigo primaveral libre de enfermedad) fue de 4.10 t/ha, y la pendiente fue de 0.038 t/ha por unidad de aumento de la severidad de la enfermedad. El tipo de trigo tuvo efecto significativo en el intercepto pero no en la pendiente: trigo inviernal tuvo, en promedio, 0.85 t/ha mas rendimiento que el trigo primaveral. ¿Cuánto sería el rendimiento de ambas variedades de trigo con 0, 1, 10 o 20% de severidad de la enfermedad? rto_prim_sev &lt;- rto_prim_0 &lt;- rto_inv_sev &lt;- rto_inv_0 &lt;- Algunos cálculos sqrt(3) # 3^0.5 2^(1/3) # ^(1/n) log(10) log(10, base=10) round(4.3478, digits=3) # ceiling(4.3478) floor(4.3478) que pasa cuando redondeamos a 0 digitos 4.5 y 3.5? # Ej 1: 5 + (3 * 10) %/% 3 == 15 # Ej 2: 4.1 - 0.038 * 10; (1-(3.72/4.1))*100 2.2 Funciones Una función es un conjunto de sentencias organizadas conjuntamente para realizar una tarea específica. Los paquetes son básicamente un set de funciones generadas por los autores de los mismos pero el usuario puede crear sus propias funciones. La sintaxis básica de una función de R es la siguiente: nombre_funcion &lt;- function(arg_1, arg_2, ...) { cuerpo_de_la_función output # return() } Las diferentes partes de una función son: Nombre de la función: este es el nombre real de la función. Se almacena en el entorno R como un objeto con este nombre. Generalmente, el nombre es intuitivo, por ejemplo, mean es la función que calcula la media, round es la funión que redondea un número. Argumentos: Un argumento es un marcador de posición. Cuando se invoca una función, se pasa un valor al argumento. Los argumentos son opcionales; es decir, una función puede no contener argumentos. También los argumentos pueden tener valores por defecto. Cuerpo de la función: el cuerpo de la función contiene una colección de sentencias que definen lo que hace la función. Valor de retorno: el valor de retorno de una función es la última expresión en el cuerpo de la función que se va a evaluar. numb &lt;- 1:6 round(mean(numb)) # floor() # ceiling() trunc() Si es necesario, el usuario puede generar sus propias funciones. Al reportar los resultados de los tests de comparaciones de medias obtenidas luego del análisis de varianza es interesante agregar en los párrafos de los resultados cuánto se incrementó o se redujo un tratamiento en referencia a un testigo en términos porcentuales. Genere una función que permita realizar estos cálculos. Tome como ayuda este link para cotejar sus resultados. perc_change &lt;- function(v1, v2) { pc &lt;- (v2-v1)/v1 *100 return(paste(pc, &quot;%&quot;)) } perc_change(80, 90) es lo mismo aumentar de 0.5 a 1 que de 1 a 1.5? cuánto es la diferencia porcentual de tener 20% de fusarium en un trigo primaveral en relación a uno invernal? Claro que en la inmensa comunidad de usuario de R, ya hubo alguien que incluyó esa función en un paquete… #percentua relative differences quantmod::Delt(80,90)*100 80+(80*0.125) quantmod::Delt(90,80)*100 90+(-90*0.1111111) Otro ejemplo de la utilidad de estas funciones “user-defined” es la preparación de soluciones partiendo de un stock o fuente a diluir, usando la equivalencia: \\[c1 * v1 = c2 * v2\\] Obviamente tanto \\(c1;c2\\), como \\(v1;v2\\), están en las mismas unidades. Para nuestra comodidad \\(c=\\%\\) y \\(v=ml\\). Nos indican que preparemos 500 ml de una solución desinfectante de NaOCl al 5%, partiendo de una lavandina concentrada (55 g Cl/L). La pregunta que del millón es: ¿qué volumen de lavandina preciso? Por lo tanto debemos despejar V1 de la equivalencia, o sea, sería nuestro output de nuestra función. Empecemos los cálculos: Si el NaOCl tiene un peso molecular de 74.5 g y el Cl pesa 35.5 g, este representa el 47.6% de la molécula de NaOCl. Por lo tanto podemos decir que la lavandina comercial posee x NaOCl = Cl/0.476 en 1 L, o bien x NaOCl % = x NaoCl/10 Si deseamos preparar 500 ml de NaOCl al 5% para la desinfección (2.5% de Cl activo, aprox.) debemos obtener: \\[v1 = (c2*v2)/c1\\] vol_lavandina &lt;- function(c1, c2, v2){ c1 &lt;- (c1/0.476)/10 # pasar g/L a % c2 &lt;- c2 # concentración que me pide el protocolo (%) v2 &lt;- v2 # volumen de la solución que deseo (ml) v1 &lt;- (c2*v2)/c1 # aliquota que debo usar return(paste(&quot;Coloque&quot;, round(v1,1), &quot;ml de lavandina y enrase con agua hasta completar&quot;, v2, &quot;ml&quot;)) } vol_lavandina(55, # g cloro / L (Lavandina) 5, # % ClONa deseada 500) # ml de la solución deseada #&gt; [1] &quot;Coloque 216.4 ml de lavandina y enrase con agua hasta completar 500 ml&quot; Ej: Generar funciones que automaticen los cálculos de: i) Pasar un muestreo de espigas/m a kg/ha (inputs: metros muestreados, ancho de hileras, espigas obtenidas, peso seco medio de espiga) ii) Rendimiento de soja ajustado 13,5% humedad (inputs: tamaño de parcela; kg de soja; humedad) iii) Grados celsius a fahrenheit iv) Cálculo de dosis de urea a fertilizar en un trigo al macollaje (inputs: N disponible, rinde objetivo, N/Ton de grano, % de N en fertilizante) v) cálculo de kg de semilla a sembrar (inputs: densidad objetivo; P1000; PG%) 2.3 Tablas resumen Table 2.1: Operadores aritméticos Operador Detalle x + y Suma de x e y x - y Resta de x menos y x * y Multiplicación x / y División de x por y x %/% y Parte entera de la división de x por y x %% y Resto de la división de x por y x ^ y x elevado a y-ésima potencia (equivalente a **) Table 2.2: Operadores lógicos Operador Prueba.lógica x &lt; y x menor que y? x &lt;= y x menor o igual que y? x &gt; y x mayor que y? x &gt;= y x mayor o igual que y? x == y x igual que y? x != y x diferente que y? Table 2.3: Funciones matemáticas Operador Detalle sqrt(x) raiz de x exp(y) exponencial de y log(x) logaritmo natural de x = ln log10(x) logaritmo base 10 de x sum(x) suma todos los elementos de x prod(x) producto de todos los elementos de x round(x, n) redondea x a n-digitos Más hotkeys Table 2.4: Algunos atajos comúnmente usados Teclas Detalle Alt+Shift+K panel de todos los atajos Ctrl+Z / Ctrl+Shift+Z undo/redo Alt+ - &lt;- Ctrl+r corre la línea/bloque completa de código Ctrl+l limpia la consola Ctrl+Shift+c silencia la línea de código Ctrl+Shift+d duplica la línea de código Ctrl+i indexa el bloque de código Referencias "],
["03-data_type.html", "3 Datos: tipos y estructuras 3.1 Tipos de datos 3.2 Estructura de datos", " 3 Datos: tipos y estructuras En términos genéricos, todos los elementos que maneja R son objetos: un valor numérico es un objeto, un vector es un objeto, una función es un objeto, una base de datos es un objeto, un gráfico es un objeto… Para realizar un uso eficiente de R es preciso entender y aprender a manipular bien las distintas clases de objetos que maneja el programa. En esta sección nos vamos a ocupar particulamente de aquellos objetos que R utiliza para representar datos: valores, vectores, matrices, dataframes y listas. 3.1 Tipos de datos La unidad básica de datos en R es un vector, los cuales pueden ser de diferentes clases. Los que más usaremos son las siguientes cuatro clases. Clase Ejemplo numeric c(12.3, 5, 999) logical c(TRUE, FALSE) integer c(2L, 34L, 0L) character c(‘a’, ‘good’, ‘TRUE’, ‘23.4’) 3.1.1 Vectores # concatenación de elementos atómicos v &lt;- c(8, 7, 9, 10, 10, 111) class(v) (b &lt;- c(&quot;A&quot;, &quot;b&quot;)) class(b) (b1 &lt;- c(&quot;12&quot;, &quot;30&quot;)) is.numeric(b1) is.character(b1) (m &lt;- c(TRUE, FALSE, T, F)) ; class(m) # Propiedades de v # ?length length(v) summary(v) sort(v) Operaciones con vectores v - 1 # Medidas de posición mean(v) median(v) # Medidas de dispersión var(v) sd(v) sqrt(var(v)) IQR(v) range(v) max(v) min(v) sum(v) #v1 &lt;- edit(v) #typo v1 hist(v1) plot(density(v1)) p10 = quantile(v1, 0.1) abline(v = p10, col = &quot;red&quot;) summary(v) Regenerar summary() a traves de funciones individuales Cree tres nuevos vectores que sean: a) la potencia cuadrada de 3.5 de v; b) la raíz cúbica de v; c) el logaritmo natural de la diferencia de a) y b) Secuencia 1:7 seq(from = 0, to = 20, #by=2) # length=4) rep(1:3, times=3) # , each=3 3.1.2 Números aleatorios La generación de números aleatorios es en muchas ocasiones un requerimiento esencial en investigación científica. Proceder de este modo puede reducir cualquier sesgo generado por nuestra persona a la hora de seleccionar una muestra, o aplicar un tratamiento a una unidad experimental. Generar números enteros de modo aleatorio de una muestra determinada sample() sample(1:30, size=10, replace=F) #sin reposición Generar números aleatorios de una distribución específica de parámetros conocidos: runif() - números racionales aleatoriamente, uniformemente distribuidos en un intervalo num_unif &lt;- runif(100, min=3, max=4) hist(num_unif) rnorm() - números aleatorios, pertenecientes a una población con distribución normal, con parámetros μ y σ. num_norm &lt;- rnorm(100, mean=70, sd=5) hist(num_norm) Vamos a recrear estas muestras partiendo de la información contenida en la tabla (Parra-Bracamonte et al. 2007) set.seed(123) PesoNac &lt;- rnorm(23570, mean=32.2, sd=1.8) range(PesoNac) hist(PesoNac) hist(PesoNac, prob=TRUE) Propiedades de vectores Si colocáramos dos o más clases diferentes dentro de un mismo vector, R va forzar a que todos los elementos pasen a pertenecer a una misma clase. El número 1.7 cambiaría a “1.7” si fuera creado junto con “a”. y1 &lt;- c(1.7, &quot;a&quot;) ## character class(y1) y2 &lt;- c(TRUE, 0, 10) ## numeric class(y2) y3 &lt;- c(TRUE, &quot;a&quot;) ## character class(y3) y4 &lt;- c(T, F) class(y4) as.numeric(y1) as.numeric(y3) as.numeric(y4) as.logical(y2) # character &gt; numerico &gt; logico Forzando las clases explícitamente as.character(), as.numeric(), as.integer() y as.logical() Factores Conceptualmente, en R, los factores son variables categóricas con un número finito de valores o niveles (levels). Son variables clasificadoras o agrupadoras de nuestros datos. Uno de los usos más importantes de los factores es en el modelado estadístico, dado que éstos son considerados de manera diferente a las variables contínuas. Claro ejemplo de factores son los tratamientos, por ej: fungicidas, genotipos, bloques, etc. Los niveles de un factor pueden estar codificados como valores numéricos o como caracteres (labels). Independientemente de que el factor sea numérico o caracter, sus valores son siempre almacenados internamente por R como números enteros, con lo que se consigue economizar memoria. Podemos comprobar que la ordenación de los niveles es simplemente alfabética. clones = c(&quot;control&quot;, &quot;B35&quot;, &quot;A12&quot;, &quot;T99&quot;, &quot;control&quot;, &quot;A12&quot;, &quot;B35&quot;, &quot;T99&quot;, &quot;control&quot;, &quot;A12&quot;, &quot;B35&quot;, &quot;T99&quot;, &quot;control&quot;) class(clones) levels(clones) clones_f = factor(clones) levels(clones_f) table(clones_f) Las variables numéricas y de caracteres se pueden convertir en factores (factorizar), pero los niveles de un factor siempre serán valores de caracteres. Podremos verlo en el siguiente ejemplo: vec &lt;- c(3, 5, 7, 1) sum(vec);mean(vec) vec_f &lt;- factor(vec) vec_f levels(vec_f) sum(vec_f);mean(vec_f) vec_n &lt;- as.numeric(vec_f) vec_f vec_n sum(vec_n); mean(vec_n) ¿Cómo hizo la transformación R? Hemos recuperado los valores numéricos originales (vec)? que representan los números codificados por R en vec_f? vec_f1 = as.numeric(as.character(vec_f)) sum(vec_f1);mean(vec_f1) Condición # ifelse(condición, valor_si_TRUE, valor_si_FALSE) ifelse(y&lt;2, &quot;Low&quot;, &quot;High&quot;) Se evaluaron 10 clones de porta-injertos de cítricos según su resistencia a Gomosis del Tronco (Phytophthora parasitica). Los diámetros de la lesión (cm) en el punto de inoculación fueron: 3, 6, 1, 10, 3, 15, 5, 8, 19, 11. Crear un vector “resist” con las categorías S o R, “S” aquellos clones con lesiones por encima de la mediana, y “R” clones con lesiones por debajo de la mediana. Indexación y &lt;- 1:10 y[ ] y[2] y[1:3] Seleccione los elementos 1° y 3° 3.1.3 Valores especiales Existen valores reservados para representar datos faltantes, infinitos, e indefiniciones matemáticas. NA (Not Available) significa dato faltante/indisponible. El NA tiene una clase, o sea, pueden ser NA numeric, NA character, etc. y &lt;- c(2, 4, NA, 6) is.na(y) Calcule el promedio de y (use la ayuda de R en caso necesario)mean(y) NaN (Not a Number) es el resultado de una operación matemática inválida, ej: 0/0 y log(-1). Un NaN es un NA, pero no recíprocamente. 0/0 is.nan(0/0) is.na(0/0) NULL es el vacío de R. Es como si el objeto no existiese a = NULL a Inf (infinito). Es el resultado de operaciones matemáticas cuyo límite es infinito, es decir, es un número muy grande, por ejemplo, 1/0 o 10^310. Acepta signo negativo -Inf. 1/0 1/Inf 3.2 Estructura de datos 3.2.1 Data frames Conjunto de observaciones (filas) y variables (columnas). A diferencia que en las matrices, las columnas pueden tener diferentes tipos (clases) de variables como por ejemplo numéricas, categóricas, lógicas, fechas. Un dataframe es completo con dimensiones n_fila x p_columna, donde: 1- Cada fila debe contener toda la info de la unidad experimental que se está evaluando 2- Cada columna representa una variable (descriptiva o respuesta) 3- Cada celda debe tener su observación (en caso de faltar el dato será un NA) En numerosos paquetes de R, hay data frames disponibles para ejemplos de aplicación de funciones. Un ejemplo muy usado, que está en el paquete base es el dataset “iris”. ?iris View(iris) # ya activo desde inicio de sesión por default hacer lo mismo con los respectivos shortcuts Explore el dataset iris con las siguientes funciones con iris y anote sus resultados: dim(); head(); tail();names(); str(); summary() Filtrado de datasets data[fila, columna] iris[1,] iris[,1] iris[1,1] iris$Sepal.Length levels(iris$Species) identical(iris$Petal.Width, iris[,2]) Selecione: i) la segunda fila; ii) la segunda columna; iii) la observación ubicada en la 2° fila y 3° columna; iv) las observaciones de las líneas 50 a 60 de las columnas 3 y 4; v) las observaciones de las líneas 50 a 60 de las columnas 2 y 4. 3.2.2 Listas Objetos que aceptan elementos de clases diferentes. x &lt;- list(a = 1:5, b = c(&quot;a&quot;, &quot;b&quot;), c = TRUE) x (Más info de subsetting elementos de una lista aquí) x$a # x[1] # #sum(x[1]) x[[1]] # sum(x[[1]]) x[&quot;c&quot;] # 3.2.3 Matrices Indicamos el número de filas con el argumento nrow y con ncol el número de columnas; luego indicamos qué valores forman la matriz (del 1 al 9), y le hemos pedido a R que use esos valores para rellenar la matriz A por filas con byrow=TRUE. La matriz A así construida es: A &lt;- matrix(nrow=3, ncol=3, c(1,2,3,4,5,6,7,8,9), byrow=TRUE) Al igual que para los dataframes, se pueden seleccionar partes de una matriz utilizando los índices de posición [fila, columna] entre corchetes. A[2,3] # Se selecciona el valor de la fila 2, columna 3 Referencias "],
["04-importar.html", "4 Importación de datos 4.1 Vías de importación 4.2 Importación múltiple", " 4 Importación de datos Luego del planteo de hipótesis y planificación experimental, la toma de datos es una etapa determinante para el resto del flujo de trabajo. Un buen diseño experimental, con correcta toma de datos de calidad, no garantizan, pero sí aumentan significativamente las probabilidades que nuestro trabajo goce de buen porvenir. Conocer las distintas etapas del workflow de investigación confiere la gran ventaja de poder pensar nuestras acciones como parte de un todo, y no como algo aislado. Por ejemplo, una planilla de campo de papel de formato apaisado (“wide”) puede que aún no esté lista para ser analizada, pero este formato confiere ciertas ventajas prácticas (confección de planilla de papel, control interno de las evaluaciones, pasaje a planilla electrónica). Por lo tanto en una siguiente etapa luego de la importación al entorno de nuestra sesión, puede que necesitemos re-estructurarla y asi poder continuar hacia la exploración. Podemos tomar esta planilla modelo, para entender cómo es una planilla para ser analizada en R. Veamos 4 Principios básicos de buenas prácticas en la elaboración de planillas de datos - Adaptado de (Broman and Woo 2018) Como regla global, y siguiendo lo ya comentado en la sección de data frames, columnas (verticales) son variables y filas (horizontales) son observaciones (generalmente de unidades experimentales/sujetos individuales). 1 - Consistencia Sean creativos al nombrar las variables: usen 3-4 letras (minúsculas) por palabra y en caso de necesitar usar “_”. No usar acentos ni ñ. Nunca dejen espacios y maximicen el ahorro de letras, siempre y cuando se justifique: severidad = sev incidencia = inc rendimiento = rto hoja = hj (bien podría ser “hoja” también) planta = pl bloque = bq placa = placa temperatura = temp máxima = max En particular prefiero usar el inglés, ya que no tiene acentos ni caracteres especiales. Siempre, siempre, identifiquen hasta el más mínimo detalle de las unidades experimentales (placas, macetas, plantas dentro de las macetas, etc.), al final se recuperará en creces el tiempo extra inicialmente invertido en ello (stand-alone). Adopten siempre los mismos términos No escatimen en columnas: rep_pl -&gt; rep | pl Crear diccionario de términos: Agreguen una planilla con el detalle por extenso de las variables y sus unidades. Piensen que esa planilla la debería entender cualquier persona sin auxilio de sus propios comentarios. 2 - Rectangular Todo set de datos tiene sus dimensiones específicas: n filas - n columnas. Si se perdió alguna parcela/planta por algún motivo extra-tratamiento simplemente es un NA, y así deben definir esa observación, no poner “muerta” o “perdida”. 3 - Cero es un dato! Cero no significa ausencia de observación, en este caso podemos usar “NA”, “-”, “.” o dejar en blanco (si se usa .xlsx) En preferencia, llenen todas las celdas, pero siempre un solo dato por celda… 4 - Planilla plana -&gt; DATOS CRUDOS SIN FÓRMULAS no combinar celdas no resaltar no hacer bordes sin negritas caracteres puros 4.1 Vías de importación Son múltiples las necesidades y vías de importación de datos a nuestro entorno de sesión de R. Principalmente usaremos planillas Excel guardados en nuestra computadora. Estos pueden estar guardados en formato .xlsx (planillas tradicionales) o .csv (texto separado con comas, mucho más livianos). Importamos los datos del curso: usethis::use_zip( &quot;https://github.com/juanchiem/R_Intro/raw/master/data/data.zip&quot;) La forma más rápida es vía clicks de mouse en el panel de entorno de la sesión: Buscan el archivo a importar en el explorador de archivos del panel multipropósito de RStudio Hacen click sobre el archivo Seleccionan “import dataset” Configuran las opciones de importación y copian el código generado y dan import O bien desde código del script: Archivos Excel Importemos los datos “crudos” (planillas de campo). Via clicks y pegamos los códigos auto-generados en nuestro script library(readxl) soja &lt;- read_excel(&quot;data/soja.xls&quot;) canola &lt;- read_excel(&quot;data/canola_maculas.xlsx&quot;) olivo &lt;- read_excel(&quot;data/olivo_xylella.xls&quot;) Dataset olivo_xylella Datos simulados de muestreos de severidad de xylella en localidades productoras de olivo en Córdoba y La Rioja. Dataset canola_phoma Experimento de canola conducido en Balcarce, donde fueron testeados 10 fungicidas (mas un control sin protección con fungicida) con 3 bloques en que se registró el progreso de manchas foliares de Phoma lingam a través del tiempo (tiempo térmico desde la detección de la primera mancha), y la severidad del consiguiente cancro desarrollado en la base del tallo. Archivos de texto .csv dat &lt;- read.csv(&quot;nombre_del_archivo.csv&quot;, header = TRUE, sep = &quot;,&quot;, dec = &quot;.&quot;)# puede variar el símbolo de cómo se separan las columnas. Siempre chequear el banco de datos importados. dat &lt;- readr::read_csv(&quot;ruta/nombre_del_archivo.csv&quot;) Desde clipboard Muchas veces necesitamos replicar rápidamente un fragmento del dataset desde Excel, o bien un vector lo que es posible mediante: {datapasta} - Package + addin install.packages(&quot;datapasta&quot;) Desde google sheets: # install.packages(&quot;gsheet&quot;) url &lt;- &quot;https://docs.google.com/spreadsheets/d/1NQ7nd2pOPQYaLzJs1D2-aOB6LDKzv9kjOcKaNeNFjpA/edit?usp=sharing&quot; # browseURL(url) dat &lt;- gsheet::gsheet2tbl(url) dat Crear dataframes tipo SAS (bueno para crear ejemplos reproducibles): dat &lt;- read.table(header=T, text=&#39; Crop x1 x2 x3 x4 Corn 16 27 31 33 Corn 15 23 30 30 Corn 16 27 27 26 Corn 18 20 25 23 Corn 15 15 31 32 Corn 15 32 32 15 Corn 12 15 16 73 Soybean 20 23 23 25 Soybean 24 24 25 32 Soybean 21 25 23 24 Soybean 27 45 24 12 Soybean 12 13 15 42 Soybean 22 32 31 43 &#39;) Colección de datos en archivo .RData Muchas veces en una misma sesión se generan nuevos datasets a partir de uno importado. Al reiniciar una sesión deberían tenerse rápidamente disponibles todos los objetos creados en días previos, los que pueden recopilarse en un archivo de múltiples objetos “.RData” e importarse directamente desde éste. save(soja, canola, file=&quot;./data/soja_canola.RData&quot;) Para traerlos nuevamente al entorno de la sesión: load(&quot;./data/soja_canola.RData&quot;) 4.2 Importación múltiple # Adaptado de: # browseURL(&quot;https://resources.rstudio.com/webinars/programacio-n-con-r-edgar-ruiz&quot;) Muchas veces necesitamos compilar varias planillas en un solo set de datos, como por ejemplo una serie de datos meteorológicos: Supongamos que tenemos varios archivos: balcarce_2018.xlsx ; balcarce_2019.xlsx library(tidyverse) library(readxl) library(fs) archivos &lt;- dir_ls(glob = &quot;balcarce_*&quot;) #(here::here(&quot;data&quot;, &quot;balcarce&quot;), glob = &quot;*.xlsx&quot;) Usaremos la función “map()” que es una función del paquete purrr, que aplica una misma acción recursivamente a una lista de objetos que le asignemos. Ej 1 - crear un dataframe a partir de múltiples archivos (primeras hojas) archivos %&gt;% map(read_excel) # &quot;pegamos&quot; una tabla arriba de la otra, archivos %&gt;% map(read_excel) %&gt;% bind_rows() archivos %&gt;% map_dfr(read_excel) # podemos agregar: .id = &quot;archivos&quot; Ej 2 - crear un dataframe a partir de múltiples hojas dentro de uno o varios archivos. (Usaremos algunas técnicas de programación un poco más avanzadas que anida un bucle dentro de otro). # https://stackoverflow.com/questions/51200887/how-to-import-multiple-sheets-from-multiple-excel-files-into-one-list-readxl-r bce_serie &lt;- archivos %&gt;% map_df(function(x){ sheet_names &lt;- excel_sheets(x) map_df(sheet_names, ~read_excel(x, sheet = .x)) }) Referencias "],
["04-googlesheets.html", "4.3 googlesheets", " 4.3 googlesheets "],
["05-manipular.html", "5 Manipular", " 5 Manipular Muchas veces los datos que importamos ya están listos para ser explorados y analizados. Otras veces precisan ser manipulados previamente para ello. En estos casos se parte de un dataset “crudo” y se transforma hacia un dataset “analítico”. # library(tidyverse) library(readxl) soja &lt;- read_excel(&quot;data/soja.xls&quot;) canola &lt;- read_excel(&quot;data/canola_maculas.xlsx&quot;) olivo &lt;- read_excel(&quot;data/olivo_xylella.xls&quot;) tidyr y dplyr integran parte de la colección de paquetes de tidyverse y facilitan la manipulación de los data frames (Wickham and Grolemund 2016) Ambos paquetes utilizan el operador %&gt;% (pipe, tubo en español) lo que proporciona una mejor interpretación lógica: utiliza el resultado de su lado izquierdo como primer argumento de la función del lado derecho (asemejándose a una receta de torta…) Hasta el momento hemos visto que: x &lt;- c(1, 2, 3, 4) sqrt(sum(x)) Como sería su equivalente bajo la sintaxis de tidyverse? library(tidyverse) x %&gt;% sum %&gt;% sqrt Referencias "],
["05-tidyr.html", "5.1 tidyr::", " 5.1 tidyr:: Las principales funciones son: pivot_longer pivot_wider separate unite join Por lo general en la etapa de toma de datos en el campo/lab (y su consiguiente pasaje a planilla electrónica, Excel) nos resulta más cómodo que las planillas de papel tengan un formato wide. En muchas ocasiones necesitamos (para graficar o modelar) que nuestros datos estén en formato long. La función pivot_longer apila las columnas que indiquemos, re-arregando los datos de un formato “wide” a “long”: Datos soja soja &lt;- readxl::read_excel(&quot;data/soja.xls&quot;) soja %&gt;% pivot_longer( # cols = c(bk_1, bk_2, bk_3, bk_4), cols = bk_1:bk_4, # cols = starts_with(&quot;bk&quot;), names_to = &quot;bk&quot;, values_to = &quot;yield&quot;, names_prefix = &quot;bk_&quot; ) -&gt; soja_long Esto se leería: al dataset soja apilar las columnas de bk_1 a bk_4 de manera tal que los nombres de estas 4 columnas queden contenidos en una columna llamada “bk” (del inglés “block”) y a los valores de rendimiento de las mismas apilarlos en una única columna llamada yield. tidyrse encargrá de repetir los niveles de la variable trttantas veces como sea necesario… al producto resultante lo llamaremos soja_long Si bien este ejemplo no representaría demasiado trabajo en excel, pensemos en datasets de mayor dimensión como ser olivo_xylella olivo &lt;- readxl::read_excel(&quot;data/olivo_xylella.xls&quot;) dim(olivo) olivo %&gt;% # dataset wide (planilla de campo, con 30 columnas de sev por arbol individual) # le pedimos que apile las columnas conteniendo a las plantas 1 a 30 pivot_longer(`1`:`30`, # el nombre de las columnas las apile en una columna llamada &quot;tree&quot; names_to = &quot;tree&quot;, # la observaciones de severidad las apile en una columna llamada sev values_to = &quot;sev&quot;) -&gt; oli_long # el producto de este re-arreglo se llamará &quot;oli_long&quot; ftable(xtabs(~year+loc+farm, oli_long)) Datos canola_maculas canola &lt;- readxl::read_excel(&quot;data/canola_maculas.xlsx&quot;) canola %&gt;% pivot_longer(inc_15:inc_248, names_to = &quot;tt&quot;, values_to = &quot;inc&quot;, names_prefix = &quot;inc_&quot;)-&gt; can_long Compilemos los 3 datasets formato long en un solo archivo .RData: save(soja_long, can_long, oli_long, file=&quot;data/datos_curso.RData&quot;) #load(&quot;data/datos_curso.RData&quot;) (Avanzado) Datos soja_mancha mancha &lt;- readxl::read_excel(&quot;data/soja_mancha.xlsx&quot;) mancha %&gt;% pivot_wider(names_from = rep, values_from = c(sev, yield)) -&gt; mancha_wide mancha_wide %&gt;% pivot_longer(-fungic, names_to = &quot;var&quot;, values_to = &quot;val&quot;) %&gt;% separate(var, c(&#39;var&#39;, &#39;bk&#39;), sep = &#39;_&#39;, convert = TRUE) %&gt;% spread(var, val, convert = TRUE) %&gt;% mutate_at(vars(fungic:bk), as.factor) -&gt; mancha_long Otras funciones interesantes de tidyr join "],
["05-dplyr.html", "5.2 dplyr::", " 5.2 dplyr:: Los principales cinco verbos (funciones) de dplyr son: select filter mutate summarise arrange select Vamos a seleccionar las variables: study, year y fungic del archivo soja: soja_long %&gt;% select(trt, yield) # Una selección “negativa” de las variables no deseadas daría un mismo resultado: # soja_long %&gt;% # select(-bk) 5.2.1 filter Semejante a subset. Condiciones separadas por comas equivalen a &amp; de subset. Filtremos la variable fungicida (fungic) por el testigo (ZZ_CHECK): soja_long %&gt;% select(trt, yield) %&gt;% filter(trt == &#39;check&#39;) Ahora, agreguemos el trt A al dataset filtrado: soja_long %&gt;% select(trt, yield) %&gt;% filter(trt %in% c(&quot;check&quot;,&quot;A&quot;)) mutate Permite operar sobre las columnas, modificando su naturaleza o haciendo operaciones sobre ellas (incluso generando nuevas columnas a partir de pre-existentes). Creación de nuevas variables (a partir de las existentes) Supongamos que queremos analizar a yield en escala de quintal (100kg = 1qq) soja_long %&gt;% mutate(yield_qq = yield/100) %&gt;% select(-yield) Conversión de tipos de variables: Ahora que hemos re-organizado los datos, queremos chequear los tipos de variables que tiene el dataset: str(soja_long) soja_long %&gt;% mutate(yield_qq = yield/100) %&gt;% select(-yield) %&gt;% mutate_at(vars(trt, bk), as.factor) %&gt;% mutate_at(vars(yield_qq), as.numeric) -&gt; soja_long1 str(soja_long1) 5.2.2 summarise Generalmente acompañada de la función group_by la cual permite aplicar un cálculo a las observaciones agrupando por niveles de algún factor (equivale a una tabla dinámica de Excel) Veamos cuánto fue el rendimiento promedio y el desvío standard para cada fungicida a través de todos los ensayos: soja_long %&gt;% group_by(trt) %&gt;% summarise(yield_mean = mean(yield), yield_sd = sd(yield)) Calculen el rendimiento mínimo y máximo de cada tratamiento arrange Ordenar columnas soja_long %&gt;% arrange(trt, yield) %&gt;% print(n=Inf) Función subset Filtremos a la variable Species reteniendo sólo a “setosa” iris_setosa &lt;- subset(iris, Species==&quot;setosa&quot;) Filtremos a la variable Species reteniendo sólo a “setosa” + “virginica” iris_set.virginica &lt;- subset(iris, Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;)) Anteponiendo el ! a la condición estaremos aplicando la negativa de la condición. regenere iris_set.virginica usando ! para mejorar el código Agreguemos una condición: a lo anterior quedémonos con aquellas filas en que Sepal.Length &gt; 5 iris2 &lt;- subset(iris, Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;) &amp; Sepal.Length &gt; 5) iris2 dim(iris2) ¿Qué pasa si cambiamos el operador &amp; por |? iris3 &lt;- subset(iris, Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;) | Sepal.Length &gt; 5) iris3 dim(iris3) iris4 no es un codigo suscinto… reformulelo en iris5 para que identical(iris4, iris5) == TRUE iris4 &lt;- subset(iris, !(Species %in% c(&quot;setosa&quot;, &quot;virginica&quot;) | Sepal.Length &gt; 5) ) iris4 dim(iris4) "],
["05-stringr.html", "5.3 stringr::", " 5.3 stringr:: "],
["05-lubridate.html", "5.4 lubridate::", " 5.4 lubridate:: blabla "],
["06-visualizar.html", "6 Visualizar 6.1 Ambas variables contínuas 6.2 Comparación de niveles de factores", " 6 Visualizar La visualización de datos es una pieza fundamental del flujo de trabajo del científico, tanto para explorar sus observaciones, como para explicar/comunicar sus resultados e ideas. Es decir, dominar las herramientas de visualización resulta imprescindible para un investigador cuya materia prima son los datos. La gran comunidad de usuarios de R disponibiliza sus creaciones e incluso trabaja en extensiones que amplían la potencialidad de sus paquetes. Se podría afirmar que no hay límites para la creación. Digamos, que no importa el “¿cómo?” si no el “¿qué?” Algunas pruebas de ello son los siguientes links: The R Graph Gallery Top 50 plots Extensiones de ggplot Fundamentals of Data Visualization El paquete ggplot2 tiene una flexibilidad tal que permite generar rápidamente gráficos exploratorios así como crear figuras complejas, detalladas, de alta calidad (con fines de publicaciones científicas). Tiene una gramática propia y la idea original es que un gráfico puede ser elaborado a partir de la combinación de capas, pudiendo tener éstas diferentes bases de datos y objetos gráficos (puntos, líneas, barras, etc). Agregaremos una a una las capas mencionadas en la figura. Éstas no tienen un orden estricto, salvo la primera que debe ser ggplot() que es la función que inicializa un gráfico. A ésta estarán asociados el dataframe principal (ya que un mismo gráfico acepta tomar información de distintos datasets), y las aesthetics que pueden ser seteadas globalmente para todo el gráfico o específicamente para cada nueva capa. aesthetics Se definen con aes(). Significado de aesthetic en ggplot: “Algo que se puede ver”. Cada geom acepta un conjunto de aesthetics. Ejemplos: + position (i.e., en el eje “x” e “y”) color (color “exterior”) fill (color “interior”) shape (de los puntos) linetype size 6.1 Ambas variables contínuas library(tidyverse) iris %&gt;% ggplot(aes(x = Sepal.Length, y = Petal.Length)) geoms Objetos geométricos. Son la representación visual de las observaciones. En general los que le dan el nombre al tipo de gráfico. La lista de “geoms” aumenta día a día. iris %&gt;% ggplot(aes(x=Sepal.Length, y=Petal.Length)) + geom_point() iris %&gt;% ggplot(aes(x=Sepal.Length, y=Petal.Length)) + geom_point(aes(color = Species)) iris %&gt;% ggplot(aes(x=Sepal.Length, y=Petal.Length)) + geom_point(aes(color = Species))+ geom_smooth() iris %&gt;% ggplot(aes(x = Sepal.Length, y = Petal.Length, color = Species)) + geom_point()+ geom_smooth() facets Las facetas o “facets” permiten dividir el mismo gráfico en múltiples paneles asociados a los niveles de un factor. p &lt;- iris %&gt;% ggplot(aes(x = Sepal.Length, y = Petal.Length)) + geom_point()+ geom_smooth(method = &quot;lm&quot;)+ facet_wrap(~Species) p theme Los temas (theme) son un conjunto de opciones predefinidas sobre la apariencia de los objetos en ggplot. El tema por defecto del ggplot dibuja el gráfico sobre un fondo gris. Podemos cambiarlo a blanco y negro añadiendo el comando theme_bw(). p + theme_bw() Si deseamos explorar las distribuciones de las variables podemos optar por un histograma o por diagramas de densidad. cowplot::plot_grid( iris %&gt;% ggplot(aes(Petal.Length, fill=Species)) + geom_histogram()+ guides(fill=FALSE) , iris %&gt;% ggplot(aes(Petal.Length, fill=Species)) + geom_density(alpha=0.7) , align=&quot;h&quot; ) 6.2 Comparación de niveles de factores Los gráficos de barra, ampliamente usados en publicaciones científicas, son cada vez más criticados por “ocultar” la naturaleza de las observaciones (Drummond and Vowler 2011; Weissgerber 2015) (Sugerencia: leer el box 1 del último paper). De (Drummond and Vowler 2011): Fig 1. Many different datasets can lead to the same bar graph. The full data may suggest different conclusions from the summary statistics. The means and SEs for the four example datasets shown in Panels B–E are all within 0.5 units of the means and SEs shown in the bar graph (Panel A). p-values were calculated in R (version 3.0.3) using an unpaired t-test, an unpaired t-test with Welch’s correction for unequal variances, or a Wilcoxon rank sum test. - In Panel B, the distribution in both groups appears symmetric. Although the data suggest a small difference between groups, there is substantial overlap between groups. - In Panel C, the apparent difference between groups is driven by an outlier. - Panel D suggests a possible bimodal distribution. Additional data are needed to confirm that the distribution is bimodal and to determine whether this effect is explained by a covariate. - In Panel E, the smaller range of values in group two may simply be due to the fact that there are only three observations. Additional data for group two would be needed to determine whether the groups are actually different. A continuación presentamos algunas opciones gráficas que surgen de la combinación de medidas de posición y de dispersión. #Aprovechamos para customizar el `theme` a nuestro gusto y agregar algunos detalles: p0 &lt;- iris %&gt;% ggplot(aes(x=Species, y=Sepal.Length)) + labs(x = &quot;Iris species&quot;, y =&quot;Sepal length (cm)&quot;) + theme_light(base_size = 10) 6.2.1 Observaciones + media / mediana p1 &lt;-p0 + geom_point(shape = 1, alpha=0.2)+ stat_summary(fun= mean, #median fun.min= mean, fun.max = mean, geom = &quot;point&quot;, size = 2)+ ggtitle(&quot;Observaciones (points) &amp; media&quot;) p1 # geom_dotplot(aes(fill = Species), # Use fill = Species here not in ggplot() # binaxis = &quot;y&quot;, # which axis to bin along # binwidth = 0.1, # Minimal difference considered diffeerent # stackdir = &quot;center&quot; # Centered # ) p2 &lt;- p0 + geom_jitter(width = 0.2, alpha=0.2)+ stat_summary(fun = mean, #median fun.min= mean, fun.max = mean, geom = &quot;crossbar&quot;, size = 0.5)+ ggtitle(&quot;Observaciones (jitter) &amp; media&quot;) p2 6.2.2 Barplot + SE p3 &lt;-p0 + # geom_bar(stat=&quot;identity&quot;) + stat_summary(fun=mean, position=position_dodge(width=0.95),geom=&quot;bar&quot;, colour=&quot;black&quot;,fill=&quot;grey90&quot;)+ stat_summary(fun.data=mean_cl_normal, geom=&quot;errorbar&quot;, width=0.2) + ggtitle(&quot;Barplot &amp; SEM&quot;) # geom_text(data= let, aes(label = M, x= trt, y=1, hjust=0.5),size = 4) p3 6.2.3 Box-plot p4 &lt;-p0 + geom_boxplot(fill = &quot;grey90&quot;) + ggtitle(&quot;Boxplot &amp; mean&quot;) p4 6.2.4 Violin plot p5 &lt;-p0 + geom_violin(trim=FALSE,fill = &quot;grey90&quot;)+ ggtitle(&quot;Violin plot&quot;) p5 6.2.5 Media &amp; dispersión p6 &lt;-p0 + stat_summary(fun=&quot;mean&quot;, geom=&quot;point&quot;, size=2)+ stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, width=0.2)+ stat_summary(fun.data= mean_sdl, geom = &quot;errorbar&quot;, color=&quot;red&quot;, width=0.2)+ stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, color=&quot;blue&quot;, width=0.2)+ ggtitle(&quot;Media + SE (negro) / SD (rojo) / 95% CI (negro)&quot;) p6 cowplot::plot_grid(p1, p2, p3, p4, p5, p6, ncol = 3, nrow = 2) Referencias "],
["06-forcats.html", "6.3 forcats::", " 6.3 forcats:: Es un excelente aliado para manipular factores, principalmente cuando de graficar se trata. Sitio oficial- machete library(tidyverse) iris %&gt;% ggplot(aes(x = Species,y = Sepal.Width)) + geom_boxplot() fct_relevel A veces queremos forzar los niveles según nuestro interés, por ejemplo, queremos posicionar al tratamiento control al inicio o al final. iris %&gt;% ggplot(aes(x = fct_relevel(Species, c(&quot;virginica&quot;, &quot;setosa&quot;, &quot;versicolor&quot;)), y = Sepal.Width)) + geom_boxplot() fct_reorder Cuando queremos ver el orden de los tratamientos rankeados según la variable. iris %&gt;% ggplot(aes(x = fct_reorder(Species, Sepal.Width, .fun=median), #.desc=TRUE y = Sepal.Width)) + geom_boxplot()#+ # geom_jitter(position=position_jitter(0.1))+ # coord_flip() case_when Asociado a mutate, cuando deseamos modificar el nombre de los niveles. iris %&gt;% mutate(species_new = # `nombre_nuevo` = &quot;nombre_original&quot; case_when(Species==&quot;setosa&quot; ~ &quot;Setosa&quot;, Species==&quot;versicolor&quot; ~ &quot;Versicolor&quot;, Species==&quot;virginica&quot; ~ &quot;Virginica&quot;)) %&gt;% # TRUE ~ &quot;Virginica&quot;)) ggplot(aes(x = species_new, y = Sepal.Width)) + geom_boxplot() O queremos generar un nuevo vector categórico a partir de una variable pre-existente. iris %&gt;% mutate(sepal_categ = case_when( Sepal.Length &gt; 5.5 ~ &quot;long&quot;, Sepal.Length &gt; 5 ~ &quot;medium&quot;, TRUE ~ &quot;short&quot; )) %&gt;% ggplot(aes(x = Species, y = Sepal.Width, color = sepal_categ)) + geom_boxplot() fct_reorder2 Reordenar los nivels por su valor final cuando son graficados con otras dos variables. iris %&gt;% ggplot(aes(Sepal.Width, Sepal.Length, color = fct_reorder2(Species, Sepal.Width, Sepal.Length)))+ geom_smooth(se=F) fct_infreq Reorder factors levels by first appearance or frequency iris %&gt;% count(Sepal.Length) %&gt;% mutate(n=n %&gt;% as.factor %&gt;% fct_infreq) %&gt;% ggplot(aes(n)) + geom_bar() "],
["06-mapas.html", "6.4 Mapas", " 6.4 Mapas Cargamos paquetes library(tidyverse) library(sf) # library(rnaturalearth) # library(&quot;rnaturalearthdata&quot;) library(georefar) Para obtener un listado de provincias: get_provincias(orden = &quot;id&quot;, max = 5) Para obtener un listado de departamentos: get_departamentos(provincia = &quot;Corrientes&quot;, orden = &quot;id&quot;, max = 5) Para obtener un listado de municipios: muni &lt;- get_municipios(provincia = &quot;Buenos Aires&quot;) Para obtener un listado de localidades: get_localidades(provincia = &quot;Chubut&quot;, max = 5) Para obtener la ubicacion de un punto (reverse-geocoding): get_ubicacion(-31.6515236,-64.4358794) Provincias de Argentina theme_set(theme_bw()) arg = rnaturalearth::ne_states(country = &#39;argentina&#39;, returnclass = &quot;sf&quot;) map_arg &lt;- arg %&gt;% ggplot() + geom_sf() + geom_text(aes(longitude, latitude, label = name_fr), colour = &quot;black&quot;, size=2) Random points puntos &lt;- st_sample(arg, 30) # arg[1:3, ], 6) puntos_coords &lt;- unlist(st_geometry(puntos)) %&gt;% matrix(ncol=2, byrow=TRUE) %&gt;% as_tibble() %&gt;% setNames(c(&quot;lon&quot;,&quot;lat&quot;)) map_arg+ geom_point(data = puntos_coords, aes(x = lon, y = lat), size = 1) Tunneo fino # library(googlesheets4) # googlesheets4::gs4_auth() # dat &lt;- gs4_find(&quot;localidades_map&quot;) %&gt;% range_read() dat &lt;- tibble::tribble( ~state, ~name, ~lat, ~lon, &quot;Buenos Aires&quot;, &quot;Junin&quot;, &quot;-34.593922&quot;, &quot;-60.946446&quot;, &quot;Santiago del Estero&quot;, &quot;Santiago del Estero&quot;, &quot;-27.784444&quot;, &quot;-64.266944&quot;, &quot;Córdoba&quot;, &quot;Córdoba&quot;, &quot;-31.416667&quot;, &quot;-64.183333&quot;, &quot;Córdoba&quot;, &quot;San José de la Quintana&quot;, &quot;-31.807335&quot;, &quot;-64.416866&quot;, &quot;Mendoza&quot;, &quot;San Rafael&quot;, &quot;-34.6175&quot;, &quot;-68.335556&quot;, &quot;Misiones&quot;, &quot;Cerro Azul&quot;, &quot;-27.633535&quot;, &quot;-55.497152&quot; ) sites &lt;- dat %&gt;% mutate_at(vars(lat:lon), as.character) %&gt;% mutate_at(vars(lat:lon), as.numeric) %&gt;% st_as_sf(coords = c(&quot;lon&quot;,&quot;lat&quot;)) %&gt;% st_set_crs(4326) %&gt;% st_transform(3857) p1 &lt;- arg %&gt;% ggplot() + geom_sf() + geom_rect(xmin= -64, ymin= -40, xmax= -56, ymax= -30, fill = NA, colour = &quot;black&quot;, size = 1) + theme_void() p1 p2 &lt;- arg %&gt;% ggplot() + geom_sf() + ggrepel::geom_label_repel(data = sites, aes(label = name, geometry = geometry), stat = &quot;sf_coordinates&quot;, min.segment.length = 0)+ geom_sf(data=sites, size=1.5)+ ggspatial::annotation_scale(location = &quot;bl&quot;, width_hint = 0.3, pad_x = unit(1.5, &quot;in&quot;), pad_y = unit(0.1, &quot;in&quot;)) + ggspatial::annotation_north_arrow(location = &quot;bl&quot;, which_north = &quot;true&quot;, pad_x = unit(4.4, &quot;in&quot;), pad_y = unit(0.1, &quot;in&quot;), style = ggspatial::north_arrow_fancy_orienteering) + coord_sf(crs = st_crs(4326), # xlim = c(-64, -56.5), ylim = c(-40, -22), expand = TRUE)+ labs(x=&quot;&quot;, y=&quot;&quot;)+ theme_bw()+ theme(plot.margin=margin(r=3, unit=&quot;cm&quot;)) p2 ggdraw(p2) + draw_plot(p1, width = 0.2, height = 0.5, x = 0.8, y = 0.48) ggsave(w=85, h=100, units=&quot;mm&quot;, scale=2, dpi=150, &quot;map2.tiff&quot;) Mapa de prevalencia de enfermedades library(polAr) BSAS &lt;- get_geo(geo = &quot;BUENOS AIRES&quot;) # https://datascience.blog.wzb.eu/2019/04/30/zooming-in-on-maps-with-sf-and-ggplot2/ BSAS%&gt;% st_bbox() SEBA &lt;- st_crop(BSAS, xmin = -60, xmax = -57, ymin = -39, ymax = -37) # SEBA %&gt;% # ggplot() + # geom_sf() cancro &lt;- SEBA %&gt;% as_tibble %&gt;% mutate(preval_2015 = rnorm(18, 30, 10), preval_2016 = preval_2015*1.05 + rnorm(1, 3, 2) , preval_2017 = preval_2016*1.05 + rnorm(1, 3, 2), preval_2018 = preval_2017*1.05 + rnorm(1, 3, 2)) %&gt;% pivot_longer(preval_2015:preval_2018, names_to = &quot;anio&quot;, values_to = &quot;prevalencia&quot;, names_prefix = &quot;preval_&quot;) cancro SEBA_cancro &lt;- SEBA %&gt;% left_join(cancro, by= &quot;coddepto&quot;) #%&gt;% SEBA_cancro %&gt;% ggplot() + geom_sf(data=SEBA)+ geom_sf(aes(fill=prevalencia))+ scale_fill_gradient2(midpoint = 35, low = &#39;green2&#39;, mid = &#39;yellow&#39;, high = &#39;red3&#39;, na.value = &#39;gray95&#39;)+ facet_wrap(&quot;anio&quot;)+ labs(title = &quot;Evolución de la prevalencia del cancro del tallo de girasol&quot;, x = NULL, y = NULL, fill = &quot;Prevalencia&quot;)+ theme_bw() fina2020 &lt;- st_read(&quot;https://github.com/juanchiem/agro_data/raw/master/Sitios_experimentales_2020_Juan.kml&quot;) nc_centers &lt;- st_centroid(fina2020) bbox &lt;- expand_bbox(st_bbox(nc_centers), X = 0, Y = 150000) library(basemapR) BSAS %&gt;% ggplot() + base_map(bbox, increase_zoom = 2, basemap = &#39;google-terrain&#39;) + geom_sf(alpha = 0.1, color=alpha(&quot;red&quot;,0.1) , show.legend = FALSE)+ geom_sf(data = fina2020[1], show.legend = FALSE)+ coord_sf(xlim= c(-61, -57),ylim= c(-39,-36.5))+ theme_void() # geom_sf_label(aes(label = coddepto), label.padding = unit(1, &quot;mm&quot;)) "],
["07-referencias.html", "Referencias", " Referencias Broman, Karl W, and Kara H Woo. 2018. “Data Organization in Spreadsheets.” The American Statistician 72 (1): 2–10. Drummond, GB, and SL Vowler. 2011. “Show the Data, Don’t Conceal Them.” British Journal of Pharmacology 163 (2): 208–10. https://doi.org/10.1111/j.1476-5381.2011.01251.x. Ellison, GN, and NJ Gotelli. 2004. “A Primer of Ecological Statistics.” Sinauer, Sunderland, Massachusetts, USA. Madden, LV, and PA Paul. 2009. “Assessing Heterogeneity in the Relationship Between Wheat Yield and Fusarium Head Blight Intensity Using Random-Coefficient Mixed Models.” Phytopathology 99 (7): 850–60. Parra-Bracamonte, Gaspar Manuel, Juan Carlos Martı́nez-González, Francisco Javier Garcı́a-Esquivel, Arnoldo González-Reyna, Florencio Briones-Encinia, and Eugenia Guadalupe Cienfuegos-Rivas. 2007. “Tendencias Genéticas Y Fenotı́picas de Caracterı́sticas de Crecimiento En El Ganado Brahman de Registro de México.” Revista Cientı́fica 17 (3): 262–67. R Core Team. 2017. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Weissgerber, Natasa M. AND Winham, Tracey L. AND Milic. 2015. “Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm.” PLOS Biology 13 (4): 1–10. https://doi.org/10.1371/journal.pbio.1002128. Wickham, Hadley, and Garrett Grolemund. 2016. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. \" O’Reilly Media, Inc.\". http://r4ds.had.co.nz/. "]
]
